{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f6908e-6405-4485-9878-c0dfae144e99",
   "metadata": {},
   "source": [
    "# Data Masters Case - Machine Learning Engineer: \n",
    "## Distributing GPU Training and Deploy (Cross Workspace) using TensorFlow 2 + Spark + MLFlow\n",
    "### Marcos Vin√≠cius Lisboa Melo - BigData & Analytics - vinicius.lisboa@f1rst.com.br\n",
    "\n",
    "This notebook is used to perform requests from local environment to Deployed REST Api with the TensorFlow Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd488fc-e710-484d-87a9-e6598f7fb70a",
   "metadata": {},
   "source": [
    "### Setting an environment to perform requests\n",
    "F1rst we need to define the endpoints parameters and import all the necessary libs to perform a call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3af9eaa-7306-448e-b0e1-bd0c5f89f808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea61b194-bed1-4408-87dd-d01641e6eefd",
   "metadata": {},
   "source": [
    "Also the url, we need to create an environment variable to storage the token from API, it's not a best pratice hardcoded a token into a script. This variable was definied at Terminal and the name is `DATABRICKS_TOKEN_GCP`. To access `.env` file the bellow cell must to be executed. It's importante remember that the env var must to be definied locally with the Databricks generated token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "7a02013d-e043-456d-b348-a1444886cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "81de6f92-88b1-49e5-b17f-5b34a52bf994",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://357648146060830.0.gcp.databricks.com/model/mnist_cnn_data_masters/1/invocations'\n",
    "headers = {'Authorization': f'Bearer {os.environ.get(\"DATABRICKS_TOKEN_GCP\")}', 'Content-Type': 'application/json'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea9c3b-f1a1-4d91-aed5-c71e188bf270",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating Functions to compose data payload\n",
    "After import image it's necessary redimensionate to 28x28 pixels format and convert to gray image with just one chanel, of course. So, we need to insert the converted and resized image into a numpy array named `sample`, because this is the standard format definied at TFX documentation to request. If we have more than one image, is just necessary append this images in array. After we create the array is necessary to convert to string format to compose the request JSON message. The key `instances` is also definied in documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5dd7f7f4-2a12-48f7-9d99-fd1471adba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_formated_image(image, write_file=False, path=''):\n",
    "    expected_width = 28\n",
    "    expected_length = 28\n",
    "\n",
    "    width = expected_width/image.shape[0]\n",
    "    length = expected_length/image.shape[1]\n",
    "\n",
    "    resize_image = cv2.resize(image, (0, 0), fx=width, fy=length)\n",
    "    gray_image = cv2.cvtColor(resize_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    sample = [gray_image]\n",
    "    sample = np.array(sample)\n",
    "\n",
    "    sample_string = np.array2string(sample, separator=',').replace('\\n','')\n",
    "\n",
    "    json_string = '{\"instances\":' + sample_string + '}'\n",
    "    data_json = json.loads(json_string)\n",
    "    \n",
    "    if write_file == True:\n",
    "        json_object = json.dumps(data_json, indent=4)\n",
    "        with open(path, 'w') as outfile:\n",
    "            outfile.write(json_object)\n",
    "    \n",
    "    return data_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a184eb-58c5-41cd-907b-87638bb683b8",
   "metadata": {},
   "source": [
    "Almost at least, we need a `score_model` function to compose the request and receive response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0af1ae16-9fe3-4ef8-b454-7249f05ed0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_model(image, url=url, headers=headers):\n",
    "    \n",
    "    data_json = json.dumps(create_formated_image(image))\n",
    "    \n",
    "    response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Request failed with status {response.status_code}, {response.text}')\n",
    "    \n",
    "    prediction = response.json()['predictions']\n",
    "    prediction = np.argmax(prediction)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e7852e-e506-461e-aa3d-9e908acdbea8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Perform a predict request\n",
    "Calling `score_model` function and passing the loaded image and the default url and headers before setted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "40f03823-0d92-4486-afbd-cd99dcbf1a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('/Users/t780496/Documents/notebooks_python/data_masters/mnist_test_images/mnist_teste_2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "e3defb34-4338-4ee3-821b-df49a0020a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current prediction number is: 3\n"
     ]
    }
   ],
   "source": [
    "number = score_model(image, url, headers)\n",
    "print('Current prediction number is: '+ str(number))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
